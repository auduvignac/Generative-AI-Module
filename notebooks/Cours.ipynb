{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d979863c",
   "metadata": {},
   "source": [
    "# IA générative : Concepts, Outils, cas d'utilisation\n",
    "\n",
    "## Intro à l'IA générative\n",
    "\n",
    "L'IA générative est un sous-domaine de l'intelligence artificielle qui se concentre sur la création de contenu original, que ce soit du texte, des images, de la musique ou d'autres formes de médias. Contrairement aux systèmes d'IA traditionnels qui se contentent d'analyser et de classer des données existantes, l'IA générative utilise des algorithmes avancés pour produire de nouvelles créations basées sur des modèles appris à partir de grandes quantités de données.\n",
    "\n",
    "Exemple d'outils : \n",
    "- ChatGPT : génération de texte conversationnel et très généraliste ;\n",
    "- DALL-E : génération d'images à partir de descriptions textuelles ;\n",
    "- Perplexity : recherche sur le web (l'indexation sur le web est optimisé par rapport à chatgpt) ;\n",
    "\n",
    "Les Ia génératives il y a deux ans étaient basés sur des input/output textuels. Aujourd'hui, on peut générer des images, de la musique, des vidéos, etc. à partir de texte, d'image, de son, de video, etc.\n",
    "\n",
    "### Machine Learning vs Generative AI\n",
    "\n",
    "Le machine learning est un sous-domaine de l'IA qui se concentre sur l'apprentissage à partir de données. Il utilise des algorithmes pour identifier des modèles et faire des prédictions basées sur ces modèles. L'IA générative, quant à elle, va au-delà de la simple analyse des données en créant de nouvelles données qui imitent les caractéristiques des données d'entraînement.\n",
    "L'IA générative utilise souvent des techniques de machine learning, mais elle se concentre sur la création plutôt que sur l'analyse.\n",
    "\n",
    "$$\n",
    "\\text{Input} \\rightarrow \\text{Machine Learning} \\rightarrow \\text{Output}\n",
    "$$\n",
    "\n",
    "Machine Learning : On part d'un modèle pré entraîné en vue de faire du *fine tuning*.\n",
    "\n",
    "Tandis que l'IA générative part d'un modèle pré entraîné et va générer de nouvelles données (textes, images, sons, etc.) à partir de ce modèle et en réponse à des *prompt*.\n",
    "Les modèles d'IA génértaive sont très bons pour :\n",
    "- zero short learning : quelques données d'entraînement suffisent pour entraîner un modèle pour faire une tâche ;\n",
    "- few short learning : quelques exemples en input dans le prompt suffisent pour faire une tâche ;\n",
    "\n",
    "Le modèle va ainsi mieux comprendre ce qu'on attend de lui à partir des exemples fournis.\n",
    "\n",
    "| Aspect                           | Classic Machine Learning                                                                 | Generative AI                                                                                   |\n",
    "|----------------------------------|-------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------|\n",
    "| **Objective**                    | Learn patterns from labeled data to **predict outputs**                                   | Learn from large data to **generate new content**                                               |\n",
    "| **Training**                     | Usually trained on a **task-specific** dataset (e.g., spam detection, image classification) | Pre-trained on **massive general-purpose datasets** (e.g., Common Crawl, Wikipedia)             |\n",
    "| **Learning Paradigm**           | **Supervised learning** is common (with labels), but unsupervised and reinforcement also used | Typically uses **unsupervised/self-supervised** learning, sometimes fine-tuned                 |\n",
    "| **Interaction with New Data**   | Model must be **trained or re-trained** on specific data                                  | Can work **zero-shot, few-shot**, or be **fine-tuned** with prompts or examples                |\n",
    "| **Input → Output**              | Input data → label or prediction (e.g., input image → cat)                                | Prompt (task + optional examples) → generated output (e.g., text, image, code)                  |\n",
    "| **Examples**                    | Linear regression, Random Forest, SVM, XGBoost                                            | GPT-4, Claude, Stable Diffusion, Gemini                                                         |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c187651d",
   "metadata": {},
   "source": [
    "| Aspect                          | Apprentissage Automatique Classique                                                      | Intelligence Artificielle Générative                                                          |\n",
    "|----------------------------------|-------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------|\n",
    "| **Objectif**                     | Apprendre des motifs à partir de données étiquetées pour **prédire des résultats**        | Apprendre à partir de grandes quantités de données pour **générer du contenu**                |\n",
    "| **Entraînement**                 | Généralement entraîné sur un **jeu de données spécifique à une tâche**                    | Pré-entraîné sur des **jeux de données généralistes massifs** (ex. : Common Crawl, Wikipedia) |\n",
    "| **Paradigme d'apprentissage**   | L’**apprentissage supervisé** est courant (avec étiquettes), mais l'apprentissage non supervisé et par renforcement sont aussi utilisés | Utilise généralement l'**apprentissage non supervisé ou auto-supervisé**, parfois avec ajustement (fine-tuning) |\n",
    "| **Interaction avec nouvelles données** | Le modèle doit être **entraîné ou ré-entraîné** sur des données spécifiques              | Peut fonctionner en **zero-shot, few-shot**, ou être **ajusté** avec des prompts ou exemples   |\n",
    "| **Entrée → Sortie**             | Donnée d'entrée → étiquette ou prédiction (ex. : image → chat)                           | Prompt (tâche + exemples optionnels) → contenu généré (ex. : texte, image, code)              |\n",
    "| **Exemples**                    | Régression linéaire, Forêt aléatoire, SVM, XGBoost                                       | GPT-4, Claude, Stable Diffusion, Gemini                                                        |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d85d525d",
   "metadata": {},
   "source": [
    "|                        | **Trained ML Model**                                                                 | **LLM Zero-Shot Categorizer**                                                  |\n",
    "|------------------------|----------------------------------------------------------------------------------------|---------------------------------------------------------------------------------|\n",
    "| ✅ **Pros**             | - High precision when well-trained                                                    | - No need to gather labeled data                                               |\n",
    "|                        | - Handles subtle distinctions (e.g., *Running* vs *Training* shoes)                   | - Fast to deploy for new customers                                             |\n",
    "|                        | - Can return prediction confidence                                                    | - Easy to test & iterate with just prompts                                     |\n",
    "| ❌ **Cons**             | - Requires labeled data per customer                                                  | - Can struggle with close categories                                           |\n",
    "|                        | - Costly training & retraining                                                        | - No probability/confidence score                                              |\n",
    "|                        | - Infra needed: model storage, monitoring, scaling                                    | - May degrade if category list is large or complex                             |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c02803",
   "metadata": {},
   "source": [
    "|                        | **Modèle ML Entraîné**                                                                | **Catégoriseur LLM Zero-Shot**                                                 |\n",
    "|------------------------|----------------------------------------------------------------------------------------|---------------------------------------------------------------------------------|\n",
    "| ✅ **Avantages**        | - Haute précision lorsqu’il est bien entraîné                                         | - Pas besoin de collecter des données étiquetées                               |\n",
    "|                        | - Gère les distinctions subtiles (ex. : *chaussures de course* vs *chaussures d’entraînement*) | - Déploiement rapide pour de nouveaux clients                                  |\n",
    "|                        | - Peut retourner un score de confiance                                                | - Facile à tester et itérer avec de simples prompts                            |\n",
    "| ❌ **Inconvénients**    | - Nécessite des données étiquetées pour chaque client                                 | - Peut avoir du mal avec des catégories proches                                |\n",
    "|                        | - Entraînement et réentraînement coûteux                                              | - Pas de score de probabilité/confiance                                        |\n",
    "|                        | - Infrastructure nécessaire : stockage, surveillance, mise à l’échelle                | - Peut se dégrader si la liste des catégories est longue ou complexe           |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "963d71e6",
   "metadata": {},
   "source": [
    "## Focus sur les LLM : architectures et fonctionnement\n",
    "\n",
    "![Preprocessing and Vectorization](Figures/NLP_0.png)\n",
    "\n",
    "### 1. Preprocessing\n",
    "\n",
    "This is the first step where raw text is cleaned and prepared for further processing:\n",
    "\n",
    "- **Tokenization**: Splitting text into individual units (words, phrases, symbols).  \n",
    "  - *Example*: `\"The cat sat\"` → `[\"The\", \"cat\", \"sat\"]`\n",
    "\n",
    "- **Lemmatization**: Converting words to their base or dictionary form.  \n",
    "  - *Example*: `\"running\"` → `\"run\"`\n",
    "\n",
    "- **Stop words removal**: Removing common words that don’t add much meaning.  \n",
    "  - *Example*: `\"is\"`, `\"the\"`, `\"and\"`\n",
    "\n",
    "These steps help reduce noise and dimensionality in the text data.\n",
    "\n",
    "### 2. Vectorization\n",
    "\n",
    "After preprocessing, textual data must be converted into numerical format so algorithms can process it:\n",
    "\n",
    "- **Word Embedding**: Representing each word as a dense vector in a semantic space (e.g., Word2Vec, GloVe).  \n",
    "  - *Example*: `\"king\"` and `\"queen\"` have similar vectors due to their contextual usage.\n",
    "\n",
    "- **Sentence Embedding**: Representing entire sentences or paragraphs as a single dense vector.  \n",
    "  - Useful for capturing meaning beyond individual words.\n",
    "\n",
    "### Embeding\n",
    "\n",
    "> **Les embeddings** sont des représentations numériques du texte où les mots similaires ont des représentations similaires.  \n",
    "> Ils sont indispensables pour que les algorithmes de machine learning comprennent le texte.\n",
    "\n",
    "![Embedding](Figures/embedding_exemple.png)\n",
    "\n",
    "Chacun des vecteurs ci-dessus sera *labellisés* en vue de faire de l'apprentissage supervisé.\n",
    "- **Word2Vec**: Trains a model to predict a word based on its context (Skip-Gram) or vice versa (CBOW).\n",
    "![Embedding](Figures/word2Vec.png)\n",
    "\n",
    "\n",
    "- **GloVe**: Uses global word co-occurrence statistics to create embeddings.\n",
    "- **FastText**: Similar to Word2Vec but considers subword information, making it effective for morphologically rich languages.\n",
    "- **BERT**: Bidirectional Encoder Representations from Transformers. It uses a transformer architecture to understand the context of words in a sentence.\n",
    "- **Sentence Transformers**: Extends BERT to create embeddings for sentences or paragraphs, useful for tasks like semantic similarity.\n",
    "- **Universal Sentence Encoder**: A model that encodes sentences into high-dimensional vectors, optimized for various NLP tasks.\n",
    "- **OpenAI Embeddings**: Embeddings provided by OpenAI's models, optimized for various tasks.\n",
    "\n",
    "\n",
    "### Modèle d'embedding Ada (OpenAI) :\n",
    "\n",
    "- A été entrâiné sur plusieurs langues ;\n",
    "- Capture le sens sémantique du texte, même à travers différentes langues ; \n",
    "- Fournit des représentations contextuelles des mots, phrases ou documents.\n",
    "\n",
    "#### Comparaison des embeddings\n",
    "\n",
    "- Utilisation du Cosine Similarity pour évaluer la similarité entre deux vecteurs d'embedding.\n",
    "- Si le Cosine Similarity est proche de 1, cela signifie que les deux vecteurs sont très similaires.\n",
    "- Si en revanche le Cosine Similarity est proche de 0, cela signifie que les deux vecteurs sont très différents (i.e. orthogonaux).\n",
    "\n",
    "![Embedding Cosine](Figures/embedding_cosine.png)\n",
    "\n",
    "**Exemple :** Common Crawl : récupère tous les sites web du monde entier et les indexe (tous les mois).\n",
    "\n",
    "![Fichier d'exemple Common Crawl](Figures/common_crawl_exemple.png)\n",
    "\n",
    "### 3. Pre-Training\n",
    "\n",
    "Pre training est la phase initiale où le modèle va apprendre les *patterns*, raisonnements, *knowledge*.\n",
    "\n",
    "![LLM pre training exemple](Figures/LLM_pre_training_0.png)\n",
    "\n",
    "Semi supervisé : le *dataset* d'entraînement a été généré automatiquement.\n",
    "\n",
    "#### 1. Forward pass\n",
    "\n",
    "##### 1. Propagation avant dans le Transformer\n",
    "\n",
    "- Les tokens embarqués passent à travers plusieurs **couches de Transformer**, qui :\n",
    "  - Utilisent la **self-attention** pour capturer le contexte sur toute la séquence et « prêter attention » à certaines parties du texte.\n",
    "  - Appliquent des **réseaux neuronaux feedforward** pour enrichir les représentations.\n",
    "\n",
    "- Cela donne des **embeddings contextualisés** pour chaque token.\n",
    "\n",
    "![LLM pre training exemple](Figures/LLM_pre_training_1.png)\n",
    "\n",
    "##### 2. Prédiction (couche de sortie)\n",
    "\n",
    "- Chaque embedding contextualisé est envoyé dans une **couche dense (linéaire)**.\n",
    "- Le modèle produit une **distribution de probabilité** sur le vocabulaire pour prédire le **prochain token**.\n",
    "\n",
    "##### 3. Calcul de la perte (Loss)\n",
    "\n",
    "- Le token prédit est comparé au **token réel (vérité terrain)**.\n",
    "- Le modèle calcule la **perte par entropie croisée**, qui mesure l’erreur de prédiction.\n",
    "\n",
    "##### 4. Rétropropagation et mise à jour des poids\n",
    "\n",
    "- À partir de la perte, les gradients sont calculés pour tous les paramètres du modèle (y compris les poids d’attention, poids des FFN, embeddings).\n",
    "- La **descente de gradient** (ex. : avec Adam) met à jour les poids pour réduire les erreurs futures.\n",
    "\n",
    "> 🔁 **Répéter encore et encore avec des milliards de données d’entraînement**\n",
    "\n",
    "#### Instruction du tuning\n",
    "\n",
    "![fine tunning](Figures/fine_tuning_0.png)\n",
    "\n",
    "![fine tunning](Figures/fine_tuning_1.png)\n",
    "\n",
    "![fine tunning](Figures/fine_tuning_2.png)\n",
    "\n",
    "Dans le tableau ci-dessus les lignes dont le *ParentId* est nul correspondent à des *prompts* de type *question* et celles qui ont un *ParentId* non nul correspondent à des *prompts* de type *complétion*/*sortie*.\n",
    "\n",
    "### Instruction\n",
    "\n",
    "📘 Exemple d’échantillon d'entraînement\n",
    "Imaginons que l’instruction soit :\n",
    "```yaml\n",
    "Instruction : Traduire en français  \n",
    "Entrée : The cat is sleeping.  \n",
    "Sortie attendue : Le chat dort.\n",
    "```\n",
    "\n",
    "🧠 Entrée et sortie du modèle (sous forme de tokens)\n",
    "L’entrée complète du modèle peut être formatée comme suit :\n",
    "\n",
    "```text\n",
    "\"Translate to French\\nThe cat is sleeping.\\n\"\n",
    "```\n",
    "\n",
    "Tokenisée en identifiants numériques :\n",
    "```text\n",
    "[101, 456, 23, 178, ..., 501]\n",
    "```\n",
    "\n",
    "Les tokens de sortie cibles sont :\n",
    "\n",
    "```text\n",
    "\"Le chat dort.\"  \n",
    "→ ['Le', 'Ġchat', 'Ġdort', '.']  \n",
    "→ [2345, 9876, 5432, 13]\n",
    "```\n",
    "\n",
    "### Reinforcement Learning from Human Feedback (RLHF)\n",
    "\n",
    "L'objectif est de donner au modèle un sens des priorités.\n",
    "\n",
    "![Reinforcement learning](Figures/reinforcement_learning.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a414bec",
   "metadata": {},
   "source": [
    "## *Finetuning* et *prompt engineering*\n",
    "\n",
    "## 🔧 Qu’est-ce que le Fine-Tuning ?\n",
    "\n",
    "« Le fine-tuning (ou ajustement fin) d’un LLM consiste à prendre un grand modèle de langage pré-entraîné  \n",
    "et à poursuivre son entraînement sur un jeu de données plus petit et spécifique à un domaine.  \n",
    "Ce processus met à jour les paramètres internes du modèle (poids) afin de l’adapter  \n",
    "plus précisément à des tâches qui reflètent les caractéristiques de ces nouvelles données. » — *GPT-4o*\n",
    "\n",
    "### 🔁 Similaire à l’Instruction Tuning\n",
    "\n",
    "« Bien que le fine-tuning et l’instruction tuning impliquent tous deux un entraînement spécifique à une tâche,  \n",
    "l’instruction tuning apprend au modèle à suivre une grande variété d’instructions,  \n",
    "tandis que le fine-tuning est souvent plus ciblé et plus profondément intégré à une tâche  \n",
    "ou un domaine particulier. »  — *GPT-4o*\n",
    "\n",
    "🧠 Pourquoi faire du Fine-Tuning sur un LLM ?\n",
    "« Le fine-tuning permet à un LLM de se spécialiser dans un domaine ou une tâche spécifique.\n",
    "Par exemple, vous pouvez l'ajuster sur les données internes de votre entreprise\n",
    "ou sur un ton de communication spécifique. »\n",
    "\n",
    "« Cela permet souvent d’obtenir de bien meilleures performances sur les tâches ciblées,\n",
    "car le modèle est exposé à des données plus pertinentes et apprend leurs schémas\n",
    "et subtilités spécifiques. »\n",
    "\n",
    "⚡ Pourquoi fine-tuner plutôt que pré-entraîner un LLM ?\n",
    "« L'entraînement d’un modèle depuis zéro nécessite d’énormes ressources informatiques\n",
    "et un jeu de données massif et diversifié.\n",
    "\n",
    "Le fine-tuning, en revanche, revient à donner un coup de pouce au modèle —\n",
    "il a déjà appris les structures générales du langage.\n",
    "Le fine-tuning ne fait que concentrer son attention.\n",
    "C’est donc beaucoup plus rentable et rapide, tout en offrant de bonnes performances\n",
    "pour un cas d’usage spécifique. »\n",
    "\n",
    "Quand faut-il pré-entraîner un LLM ?\n",
    "\n",
    "- **Langue nouvelle ou peu dotée en ressources**  \n",
    "  Lorsque la langue cible n’est pas couverte par les modèles pré-entraînés existants  \n",
    "  (ex. : un dialecte émergent ou une langue autochtone).\n",
    "\n",
    "- **Domaines très spécialisés ou peu explorés**  \n",
    "  Par exemple, des domaines avec un jargon technique pointu (juridique, biotechnologie, aérospatial)  \n",
    "  que les LLM n’ont pas encore rencontrés (ex. : faible exposition sur Internet).\n",
    "\n",
    "- **Avancées architecturales ou méthodologiques**  \n",
    "  Lorsque vous souhaitez améliorer les capacités d’un LLM en modifiant son architecture,  \n",
    "  en utilisant de nouveaux jeux de données, ou en appliquant une méthode d’apprentissage récente  \n",
    "  (ex. : Mixture of Experts, Low-Rank Adaptation).\n",
    "\n",
    "Exemple de Fine tunning d'une LLM :\n",
    "\n",
    "![Reinforcement learning](Figures/fine_tunning_LLM_example.png)\n",
    "\n",
    "## Focus sur les RAG : embedding, Vector DB, Code architecture\n",
    "\n",
    "## 📚 Principle: RAG vs Fine-Tuning\n",
    "\n",
    "**Principe** :  \n",
    "Le RAG (*Retrieval-Augmented Generation*) poursuit un objectif similaire au *fine-tuning*.\n",
    "Le but est de spécialiser le LLM dans un domaine ou une tâche précise,  \n",
    "et lui donner accès aux données de l’entreprise.\n",
    "\n",
    "**Différence** :  \n",
    "Le RAG ne modifie pas les paramètres du modèle LLM.  \n",
    "Il fait seulement **enrichir**/**augmenter** le prompt en y ajoutant des données externes pertinentes,  \n",
    "afin de fournir au LLM des connaissances et des exemples utiles à l’accomplissement de la tâche.\n",
    "\n",
    "![RAG](Figures/RAG.png)\n",
    "\n",
    "## Web application developpement\n",
    "\n",
    "## Code Walkthrough : Comment une application Flask est strucuturée ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d00c9b",
   "metadata": {},
   "source": [
    "## *Finetuning* et *prompt engineering*\n",
    "\n",
    "## 🔧 Qu’est-ce que le Fine-Tuning ?\n",
    "\n",
    "« Le fine-tuning (ou ajustement fin) d’un LLM consiste à prendre un grand modèle de langage pré-entraîné  \n",
    "et à poursuivre son entraînement sur un jeu de données plus petit et spécifique à un domaine.  \n",
    "Ce processus met à jour les paramètres internes du modèle (poids) afin de l’adapter  \n",
    "plus précisément à des tâches qui reflètent les caractéristiques de ces nouvelles données. » — *GPT-4o*\n",
    "\n",
    "### 🔁 Similaire à l’Instruction Tuning\n",
    "\n",
    "« Bien que le fine-tuning et l’instruction tuning impliquent tous deux un entraînement spécifique à une tâche,  \n",
    "l’instruction tuning apprend au modèle à suivre une grande variété d’instructions,  \n",
    "tandis que le fine-tuning est souvent plus ciblé et plus profondément intégré à une tâche  \n",
    "ou un domaine particulier. »  — *GPT-4o*\n",
    "\n",
    "🧠 Pourquoi faire du Fine-Tuning sur un LLM ?\n",
    "« Le fine-tuning permet à un LLM de se spécialiser dans un domaine ou une tâche spécifique.\n",
    "Par exemple, vous pouvez l'ajuster sur les données internes de votre entreprise\n",
    "ou sur un ton de communication spécifique. »\n",
    "\n",
    "« Cela permet souvent d’obtenir de bien meilleures performances sur les tâches ciblées,\n",
    "car le modèle est exposé à des données plus pertinentes et apprend leurs schémas\n",
    "et subtilités spécifiques. »\n",
    "\n",
    "⚡ Pourquoi fine-tuner plutôt que pré-entraîner un LLM ?\n",
    "« L'entraînement d’un modèle depuis zéro nécessite d’énormes ressources informatiques\n",
    "et un jeu de données massif et diversifié.\n",
    "\n",
    "Le fine-tuning, en revanche, revient à donner un coup de pouce au modèle —\n",
    "il a déjà appris les structures générales du langage.\n",
    "Le fine-tuning ne fait que concentrer son attention.\n",
    "C’est donc beaucoup plus rentable et rapide, tout en offrant de bonnes performances\n",
    "pour un cas d’usage spécifique. »\n",
    "\n",
    "Quand faut-il pré-entraîner un LLM ?\n",
    "\n",
    "- **Langue nouvelle ou peu dotée en ressources**  \n",
    "  Lorsque la langue cible n’est pas couverte par les modèles pré-entraînés existants  \n",
    "  (ex. : un dialecte émergent ou une langue autochtone).\n",
    "\n",
    "- **Domaines très spécialisés ou peu explorés**  \n",
    "  Par exemple, des domaines avec un jargon technique pointu (juridique, biotechnologie, aérospatial)  \n",
    "  que les LLM n’ont pas encore rencontrés (ex. : faible exposition sur Internet).\n",
    "\n",
    "- **Avancées architecturales ou méthodologiques**  \n",
    "  Lorsque vous souhaitez améliorer les capacités d’un LLM en modifiant son architecture,  \n",
    "  en utilisant de nouveaux jeux de données, ou en appliquant une méthode d’apprentissage récente  \n",
    "  (ex. : Mixture of Experts, Low-Rank Adaptation).\n",
    "\n",
    "Exemple de Fine tunning d'une LLM :\n",
    "\n",
    "![Reinforcement learning](Figures/fine_tunning_LLM_example.png)\n",
    "\n",
    "## Focus sur les RAG : embedding, Vector DB, Code architecture\n",
    "\n",
    "## 📚 Principle: RAG vs Fine-Tuning\n",
    "\n",
    "**Principe** :  \n",
    "Le RAG (*Retrieval-Augmented Generation*) poursuit un objectif similaire au *fine-tuning*.\n",
    "Le but est de spécialiser le LLM dans un domaine ou une tâche précise,  \n",
    "et lui donner accès aux données de l’entreprise.\n",
    "\n",
    "**Différence** :  \n",
    "Le RAG ne modifie pas les paramètres du modèle LLM.  \n",
    "Il fait seulement **enrichir**/**augmenter** le prompt en y ajoutant des données externes pertinentes,  \n",
    "afin de fournir au LLM des connaissances et des exemples utiles à l’accomplissement de la tâche.\n",
    "\n",
    "![RAG](Figures/RAG.png)\n",
    "\n",
    "```python\n",
    "def retrieve_and_generate(question, vectordb):\n",
    "    \"\"\"\n",
    "    Answer a 'question' based on the most similar context from the \n",
    "    vector database 'vectordb'\n",
    "    \"\"\"\n",
    "    # Find data in the vectordb similar to the question\n",
    "    context = retrieve_similar_documents(\n",
    "        question,\n",
    "        vectordb,\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        # Create a chat completion using the question and retrieved context\n",
    "        response = client.chat.completions.create(\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"\"\"\n",
    "                  Answer the question based on the context below,\n",
    "                  and if the question can't be answered based on the context,\n",
    "                  say 'I don't know'\n",
    "                  \"\"\"\n",
    "                }, \n",
    "                {\"role\": \"user\", \"content\": f\"\"\"\n",
    "                  Context:\n",
    "                  {context}\n",
    "\n",
    "                  Question:\n",
    "                  {question}\n",
    "\n",
    "                  Answer:\n",
    "                  \"\"\"}\n",
    "              ]\n",
    "          )\n",
    "      return response\n",
    "    except Exception as e:\n",
    "        return str(e)\n",
    "\n",
    "# Option 1: Using DataFrame + cosine similarity\n",
    "def retrieve_similar_documents(question, df):\n",
    "    \"\"\"\n",
    "    Create a context for a question by finding the top 3 most similar documents from the dataframe\n",
    "    Calcul de la distance à la volée\n",
    "    \"\"\"\n",
    "    # Get the embeddings for the question\n",
    "    q_embeddings = client.embeddings.create(\n",
    "        input=question, \n",
    "        engine=\"text-embedding-ada-002\"\n",
    "    )['data'][0]['embedding']\n",
    "\n",
    "    # Get the distances from the embeddings\n",
    "    df['distances'] = distances_from_embeddings(\n",
    "        q_embeddings,\n",
    "        df['embeddings'].values,\n",
    "        distance_metric='cosine'\n",
    "    )\n",
    "\n",
    "    df_result = df.sort_values('distances', ascending=True).head(3)\n",
    "\n",
    "    # Return the context\n",
    "    return \" \".join([doc for doc in df_result.document])\n",
    "\n",
    "# Option 2: Using a vector database query\n",
    "def retrieve_similar_documents(question, vectordb):\n",
    "    # Use the query method to retrieve the top 3 most similar documents\n",
    "    results = vectordb.query(\n",
    "        query_texts=[question],\n",
    "        n_results=3\n",
    "    )\n",
    "\n",
    "    # Concatenate the retrieved documents\n",
    "    context = \" \".join([doc for doc in results])\n",
    "\n",
    "    return context\n",
    "```\n",
    "\n",
    "#### Différence entre une base de données vectorielle et une base de données *standard* ?\n",
    "\n",
    "##### Recherche de similarité efficace\n",
    "\n",
    "- Les **vector stores** (magasins de vecteurs) sont conçus pour la recherche **rapide de voisins les plus proches approximatifs (ANN)** dans des espaces de grande dimension (par ex. : embeddings de 384 ou 768 dimensions).\n",
    "- Ils permettent aux systèmes de trouver les résultats **sémantiquement les plus similaires** plutôt que de simples correspondances de mots-clés.\n",
    "- Essentiel pour les **applications IA/ML** comme la recherche sémantique, les moteurs de recommandation et **le RAG** (retrieval-augmented generation).\n",
    "\n",
    "**Exemple** : Vous cherchez « Comment payer ses impôts ? » — un vector store peut renvoyer un document intitulé « Guide de déclaration de revenus » car il est **sémantiquement similaire**, même si les mots ne correspondent pas exactement.\n",
    "\n",
    "##### Passage à l’échelle\n",
    "\n",
    "- Les **vector stores** sont conçus pour **passer à l’échelle sur des millions ou milliards de vecteurs**, tout en renvoyant des résultats en quelques millisecondes.\n",
    "- Ils prennent souvent en charge une **architecture distribuée** et l’**accélération matérielle** (ex. : GPU, SIMD).\n",
    "- Cela les rend particulièrement adaptés aux applications telles que les **chatbots**, la **recherche documentaire**, et les **bases de connaissances IA à grande échelle**.\n",
    "\n",
    "## Web application developpement : Front-end et Back-ends\n",
    "### API Principles\n",
    "\n",
    "![API Principles](Figures/API_principles.png)\n",
    "\n",
    "Exemple de structure d'une API :\n",
    "\n",
    "`app.py` :\n",
    "\n",
    "```python\n",
    "from flask import Flask, request, jsonify, render_template\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Dummy function to simulate getting car details\n",
    "def get_car_details(departure, destination):\n",
    "    # This is where you'd implement the logic to get the car details.\n",
    "    # For this example, we'll just return some hardcoded data.\n",
    "    return {\n",
    "        \"type_of_car\": \"UberX\",\n",
    "        \"price\": \"$10-13\",\n",
    "        \"gps_coordinates\": {\"lat\": 40.7128, \"long\": -74.0060}\n",
    "    }\n",
    "\n",
    "@app.route('/get_car', methods=['GET'])\n",
    "def get_car():\n",
    "    departure_address = request.args.get('departure_address')\n",
    "    destination_address = request.args.get('destination_address')\n",
    "\n",
    "    car_details = get_car_details(departure_address, destination_address)\n",
    "    return jsonify(car_details)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True)\n",
    "```\n",
    "\n",
    "`index.html` :\n",
    "\n",
    "```html\n",
    "```html\n",
    "<!DOCTYPE html>\n",
    "<html lang=\"en\">\n",
    "<head>\n",
    "    <meta charset=\"UTF-8\">\n",
    "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
    "    <title>Ride Details</title>\n",
    "</head>\n",
    "<body>\n",
    "\n",
    "    <h2>Get Ride Details</h2>\n",
    "\n",
    "    <label for=\"departure_address\">Departure Address:</label>\n",
    "    <input type=\"text\" id=\"departure_address\" name=\"departure_address\"><br><br>\n",
    "\n",
    "    <label for=\"destination_address\">Destination Address:</label>\n",
    "    <input type=\"text\" id=\"destination_address\" name=\"destination_address\"><br><br>\n",
    "\n",
    "    <button onclick=\"getRideDetails()\">Get Details</button>\n",
    "\n",
    "    <h3>Ride Details</h3>\n",
    "    <div id=\"rideDetails\"></div>\n",
    "\n",
    "    <script>\n",
    "        function getRideDetails() {\n",
    "            var departureAddress = document.getElementById('departure_address').value;\n",
    "            var destinationAddress = document.getElementById('destination_address').value;\n",
    "\n",
    "            fetch(`/get_car?departure_address=${departureAddress}&destination_address=${destinationAddress}`)\n",
    "                .then(response => response.json())\n",
    "                .then(data => {\n",
    "                    var details = `\n",
    "                        <p>Type of Car: ${data.type_of_car}</p>\n",
    "                        <p>Price: ${data.price}</p>\n",
    "                        <p>GPS Coordinates: lat ${data.gps_coordinates.lat} long ${data.gps_coordinates.long}</p>\n",
    "                    `;\n",
    "                    document.getElementById('rideDetails').innerHTML = details;\n",
    "                })\n",
    "                .catch(error => console.error('Error:', error));\n",
    "        }\n",
    "    </script>\n",
    "\n",
    "</body>\n",
    "</html>\n",
    "```\n",
    "\n",
    "Côté backend on a une route par laquelle on va pouvoir afficher le résultat du code html.\n",
    "\n",
    "```python\n",
    "@app.route('/')\n",
    "def index():\n",
    "    return render_template('index.html')\n",
    "```\n",
    "\n",
    "# 📁 Flask Project Overview\n",
    "\n",
    "## Root Directory: `YourFlaskApp/`\n",
    "\n",
    "- `app.py`  \n",
    "  → Main Flask application file.\n",
    "\n",
    "- `requirements.txt`  \n",
    "  → Lists Python dependencies for the project.\n",
    "\n",
    "---\n",
    "\n",
    "## 📂 Static Files: `static/`\n",
    "\n",
    "- `css/style.css`  \n",
    "  → Custom stylesheets.\n",
    "\n",
    "- `js/script.js`  \n",
    "  → Client-side JavaScript logic.\n",
    "\n",
    "- `images/logo.png`  \n",
    "  → Image assets (e.g., logos, icons).\n",
    "\n",
    "---\n",
    "\n",
    "## 📂 Templates: `templates/`\n",
    "\n",
    "- `index.html`  \n",
    "  → Main homepage template.\n",
    "\n",
    "- `layout.html`  \n",
    "  → Base layout template used with `{% extends \"layout.html\" %}`.\n",
    "\n",
    "- `other_template.html`  \n",
    "  → Any additional HTML template for other views/pages.\n",
    "\n",
    "\n",
    "## Code Walkthrough : Comment une application Flask est strucuturée ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ede48b",
   "metadata": {},
   "source": [
    "# Projet\n",
    "\n",
    "Créer une application avec OpenAI et Cursor\n",
    "\n",
    "Ce projet explore le développement d'une application web basée sur OpenAI API pour créer des features d'IA générative."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
