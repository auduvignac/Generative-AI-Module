{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting started\n",
    "\n",
    "<table align=\"left\">\n",
    "  <td>\n",
    "    <a href=\"https://colab.research.google.com/github/auduvignac/Generative-AI-Module/blob/main/notebooks/getting_started.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import configparser\n",
    "\n",
    "# Third-party imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from flask import Flask\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "\n",
    "# Pandas configuration\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_csv = \"https://raw.githubusercontent.com/auduvignac/Generative-AI-Module/refs/heads/main/data/twitter_data_clean_sample.csv\"\n",
    "data_sample = pd.read_csv(\"../data/twitter_data_clean_sample.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_tweet</th>\n",
       "      <th>company_tweet</th>\n",
       "      <th>company</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ordered this around 2am Friday morning and it made it here already... good job @115830 https://t.co/XXMuII3QwQ</td>\n",
       "      <td>@383517 I am very happy to hear this Pablo:) I hope you enjoy your order.^GA</td>\n",
       "      <td>AmazonHelp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@AmazonHelp what does \"ships in 1-3 weeks\" actually mean? Do you have the item I want in stock or not? Items like this have given me issues</td>\n",
       "      <td>@274096 If your item will ship in 1-3 weeks, this means the item is not in stock and needs to be ordered from our distributor. More info here: https://t.co/V7JYyWd9JF ^RA</td>\n",
       "      <td>AmazonHelp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@115821 // Email from Representative not correct.  There was someone to receive package.  Whoever said different at @118706 is lying.</td>\n",
       "      <td>@528375 I'm sorry you haven't received your package. We'd like to help. Please contact us here: https://t.co/hApLpMlfHN ^AY</td>\n",
       "      <td>AmazonHelp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>je l’ai déjà l’application amazon jdevrais être immunisé de vos pubs de merde @115821</td>\n",
       "      <td>@792999 3/3  Ensuite décochez à nouveau les cases que vous aviez sélectionnées.  N'oubliez pas de \"Valider\" pour effectuer vos modifications.  \\nNous espérons que ces informations vous seront utiles.</td>\n",
       "      <td>AmazonHelp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I must say @115830, a package left under a doormat which is full of holes, in the middle of a downpour, is not the best idea #wetelectronics</td>\n",
       "      <td>@776873 I apologize for how your delivery was handled, that is not the experience we want our customers to have. Which courier was assigned delivery of that package, as shown in the order details here:  https://t.co/aaDyEz1VgE ^CH</td>\n",
       "      <td>AmazonHelp</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                 customer_tweet  \\\n",
       "0                                Ordered this around 2am Friday morning and it made it here already... good job @115830 https://t.co/XXMuII3QwQ   \n",
       "1   @AmazonHelp what does \"ships in 1-3 weeks\" actually mean? Do you have the item I want in stock or not? Items like this have given me issues   \n",
       "2         @115821 // Email from Representative not correct.  There was someone to receive package.  Whoever said different at @118706 is lying.   \n",
       "3                                                         je l’ai déjà l’application amazon jdevrais être immunisé de vos pubs de merde @115821   \n",
       "4  I must say @115830, a package left under a doormat which is full of holes, in the middle of a downpour, is not the best idea #wetelectronics   \n",
       "\n",
       "                                                                                                                                                                                                                            company_tweet  \\\n",
       "0                                                                                                                                                            @383517 I am very happy to hear this Pablo:) I hope you enjoy your order.^GA   \n",
       "1                                                              @274096 If your item will ship in 1-3 weeks, this means the item is not in stock and needs to be ordered from our distributor. More info here: https://t.co/V7JYyWd9JF ^RA   \n",
       "2                                                                                                             @528375 I'm sorry you haven't received your package. We'd like to help. Please contact us here: https://t.co/hApLpMlfHN ^AY   \n",
       "3                                 @792999 3/3  Ensuite décochez à nouveau les cases que vous aviez sélectionnées.  N'oubliez pas de \"Valider\" pour effectuer vos modifications.  \\nNous espérons que ces informations vous seront utiles.   \n",
       "4  @776873 I apologize for how your delivery was handled, that is not the experience we want our customers to have. Which courier was assigned delivery of that package, as shown in the order details here:  https://t.co/aaDyEz1VgE ^CH   \n",
       "\n",
       "      company  \n",
       "0  AmazonHelp  \n",
       "1  AmazonHelp  \n",
       "2  AmazonHelp  \n",
       "3  AmazonHelp  \n",
       "4  AmazonHelp  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sample.company.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. How to use the OpenAI API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a `config.ini` file containing your OpenAI API credentials\n",
    "\n",
    "    \n",
    "    [OPENAI_API]\n",
    "    OPENAI_KEY = key\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading OpenAI API key from configuration file\n",
    "config = configparser.ConfigParser()\n",
    "config.read('../config.ini') #Path to your configuration file\n",
    "OPENAI_KEY = config.get('OPENAI_API', 'OPENAI_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=OPENAI_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ChatCompletion : Get GPT response to your prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Documentation : https://platform.openai.com/docs/guides/text-generation/chat-completions-api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "message = \"Placed an order for some headphones early Monday morning, and they've arrived in 2 days... impressive service!\"\n",
    "company = \"Amazon\"\n",
    "\n",
    "print(f\"Tweet: {message} \\nCompany: {company}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction =  f\"\"\"\\\n",
    "You are a chatbot answering customer's messages. You are working for a company called {company}. Reply to the message below.\n",
    "#####\n",
    "Message:\n",
    "\"{message}\" \"\"\"\n",
    "print(f\"Instruction:\\n\\n{instruction}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": instruction}\n",
    "]\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=messages,\n",
    "    temperature = 0.7) # temperature ranges from 0 (deterministic) to 1 (creative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_text_vanilla = response.choices[0].message.content\n",
    "print(f\"Answer generated:\\n\\n{generated_text_vanilla}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding model : Get the embedding of a text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Documentation : https://platform.openai.com/docs/guides/embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "message_1 = \"Placed an order for some headphones early Monday morning, and they've arrived in 2 days... impressive service!\"\n",
    "message_2 = \"Ordered this around 2am Friday morning and it made it here already... good job @115830 https://t.co/XXMuII3QwQ\"\n",
    "message_3 = \"I hate Amazon!!!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(text, model=\"text-embedding-3-small\"):\n",
    "   \"\"\"Get the embedding of an input text\"\"\"\n",
    "   text = text.replace(\"\\n\", \" \")\n",
    "   return client.embeddings.create(input = [text], model=model).data[0].embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_message_1 = get_embedding(message_1)\n",
    "embedding_message_2 = get_embedding(message_2)\n",
    "embedding_message_3 = get_embedding(message_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Message 1 : {message_1}\\nEmbedding length : {len(embedding_message_1)}\\nEmbedding:\\n{embedding_message_1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare two embeddings to find similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A cosine similarity close to 1 implies that the sentence embeddings are very similar, meaning their vectors point in almost the same direction. This suggests the sentences have similar meanings or semantic content.\n",
    "\n",
    "A cosine similarity around 0 indicates that the sentence embeddings are orthogonal (or near-orthogonal) to each other in the vector space, suggesting that the sentences are unrelated or have neutral similarity.\n",
    "\n",
    "A cosine similarity close to -1 indicates that the embeddings are diametrically opposed in the vector space, suggesting that the sentences are highly dissimilar or have opposite meanings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(A, B):\n",
    "    dot_product = np.dot(A, B)\n",
    "    magnitude_A = np.linalg.norm(A)\n",
    "    magnitude_B = np.linalg.norm(B)\n",
    "    return dot_product / (magnitude_A * magnitude_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_message1_message2 = cosine_similarity(embedding_message_1, embedding_message_2)\n",
    "print(f\"Message 1 : {message_1}\\nMessage 2 : {message_2}\\n\\nSimilarity: {similarity_message1_message2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_message1_message3 = cosine_similarity(embedding_message_1, embedding_message_3)\n",
    "print(f\"Message 1 : {message_1}\\nMessage 3 : {message_3}\\n\\nSimilarity: {similarity_message1_message3}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Augment your prompt : RAG principle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Customer's Tweet to answer \n",
    "tweet = \"Placed an order for some headphones early Monday morning, and they've arrived in 2 days... impressive service!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similar message with the agent's reply\n",
    "\n",
    "message = data_sample.head(1).customer_tweet[0]\n",
    "reply = data_sample.head(1).company_tweet[0]\n",
    "company = data_sample.head(1).company[0]\n",
    "\n",
    "print(f\"Customer's Tweet: {message}\\nCompany's Tweet: {reply}\\nCompany: {company}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction =  f\"\"\"\\\n",
    "You are a chatbot answering customer's tweet. You are working for a company called Amazon. \n",
    "You are provided with an example of a similar interaction between a customer and an agent. Reply to the customer's tweet in the same tone, structure and style than the provided example.\n",
    "\n",
    "#####\n",
    "Example :\n",
    "Customer : \"{message}\"\n",
    "Agent : \"{reply}\"\n",
    "\n",
    "#####\n",
    "Tweet:\n",
    "\"{tweet}\"\n",
    "\"\"\"\n",
    "print(f\"Instruction:\\n\\n{instruction}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": instruction}\n",
    "]\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=messages,\n",
    "    temperature = 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_text = response.choices[0].message.content\n",
    "print(f\"Answer generated:\\n\\n{generated_text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vanilla answer without augmentation\n",
    "\n",
    "print(f\"Vanilla answer without augmentation:\\n\\n{generated_text_vanilla}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
